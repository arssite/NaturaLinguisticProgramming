{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPio3JfWbKV1PCH3AOz//Ca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arssite/NaturaLinguisticProgramming/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrdiZHVj-Y7r",
        "outputId": "ae951597-1dbf-4c03-9029-7f1c5e7bc890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=\"\"\"Collecting Quotes As we are going to use famous quotes as our data, we are facing easy situation, quotes are plentiful on the Internet. You probably could even buy huge repository full of quotes. But I am using a different approach, I like to vet every single one of them. I want make sure they make me feel good, I can assume that that make my community of friends on Twitter feel good as well... by prodocySo I'll share my stash of quotes with you, I'm going to pull one quote for every author. I have dozens and dozens of quotes from Albert Einstein or Richard Feynman, but here I'm on the pull one of each. I'm assuming if you like this project and you want to build your own quote machine, you will want to go out and find your own quotes, those that make you feel good.\"\"\"\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "5xjpnFYp-cO6",
        "outputId": "599fea31-b7a8-4abd-de7c-291552cd5f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Collecting Quotes As we are going to use famous quotes as our data, we are facing easy situation, quotes are plentiful on the Internet. You probably could even buy huge repository full of quotes. But I am using a different approach, I like to vet every single one of them. I want make sure they make me feel good, I can assume that that make my community of friends on Twitter feel good as well... by proxySo I'll share my stash of quotes with you, I'm going to pull one quote for every author. I have dozens and dozens of quotes from Albert Einstein or Richard Feynman, but here I'm on the pull one of each. I'm assuming if you like this project and you want to build your own quote machine, you will want to go out and find your own quotes, those that make you feel good.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM-nSuLL-wMx",
        "outputId": "3914bd9e-3576-42c2-d875-7e89149b6df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=sent_tokenize(corpus)#sentence_tokenization\n",
        "doc #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nRHr4YV_DDM",
        "outputId": "7c2bae8f-2289-40db-dce7-3f742998dda3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting Quotes As we are going to use famous quotes as our data, we are facing easy situation, quotes are plentiful on the Internet.',\n",
              " 'You probably could even buy huge repository full of quotes.',\n",
              " 'But I am using a different approach, I like to vet every single one of them.',\n",
              " \"I want make sure they make me feel good, I can assume that that make my community of friends on Twitter feel good as well... by proxySo I'll share my stash of quotes with you, I'm going to pull one quote for every author.\",\n",
              " \"I have dozens and dozens of quotes from Albert Einstein or Richard Feynman, but here I'm on the pull one of each.\",\n",
              " \"I'm assuming if you like this project and you want to build your own quote machine, you will want to go out and find your own quotes, those that make you feel good.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sent_tokenize(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIdm4QI__E3X",
        "outputId": "d6bfb030-96a6-4860-d5f5-6bed12418b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niwPQtHQAJo-",
        "outputId": "1e5f707c-b1b0-486f-9924-e8ae6896980b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*doc,end=(\"\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P8pJah7_1GA",
        "outputId": "21c314ec-ac0f-45ae-9d15-0c3a908a1a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Quotes As we are going to use famous quotes as our data, we are facing easy situation, quotes are plentiful on the Internet. You probably could even buy huge repository full of quotes. But I am using a different approach, I like to vet every single one of them. I want make sure they make me feel good, I can assume that that make my community of friends on Twitter feel good as well... by proxySo I'll share my stash of quotes with you, I'm going to pull one quote for every author. I have dozens and dozens of quotes from Albert Einstein or Richard Feynman, but here I'm on the pull one of each. I'm assuming if you like this project and you want to build your own quote machine, you will want to go out and find your own quotes, those that make you feel good.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in doc:\n",
        "  print(i,end=(\"\\n------------------------\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_b13fnK_1IG",
        "outputId": "8d78e76d-7df4-43ea-d433-7ec25b4a5108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Quotes As we are going to use famous quotes as our data, we are facing easy situation, quotes are plentiful on the Internet.\n",
            "------------------------\n",
            "You probably could even buy huge repository full of quotes.\n",
            "------------------------\n",
            "But I am using a different approach, I like to vet every single one of them.\n",
            "------------------------\n",
            "I want make sure they make me feel good, I can assume that that make my community of friends on Twitter feel good as well... by proxySo I'll share my stash of quotes with you, I'm going to pull one quote for every author.\n",
            "------------------------\n",
            "I have dozens and dozens of quotes from Albert Einstein or Richard Feynman, but here I'm on the pull one of each.\n",
            "------------------------\n",
            "I'm assuming if you like this project and you want to build your own quote machine, you will want to go out and find your own quotes, those that make you feel good.\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#para_to_word\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "-wtJYMoD_xFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word=word_tokenize(corpus)\n",
        "word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWQ-LdyuBfiD",
        "outputId": "79271ac7-4334-4cd0-9f58-817eeaf0c298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting',\n",
              " 'Quotes',\n",
              " 'As',\n",
              " 'we',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'use',\n",
              " 'famous',\n",
              " 'quotes',\n",
              " 'as',\n",
              " 'our',\n",
              " 'data',\n",
              " ',',\n",
              " 'we',\n",
              " 'are',\n",
              " 'facing',\n",
              " 'easy',\n",
              " 'situation',\n",
              " ',',\n",
              " 'quotes',\n",
              " 'are',\n",
              " 'plentiful',\n",
              " 'on',\n",
              " 'the',\n",
              " 'Internet',\n",
              " '.',\n",
              " 'You',\n",
              " 'probably',\n",
              " 'could',\n",
              " 'even',\n",
              " 'buy',\n",
              " 'huge',\n",
              " 'repository',\n",
              " 'full',\n",
              " 'of',\n",
              " 'quotes',\n",
              " '.',\n",
              " 'But',\n",
              " 'I',\n",
              " 'am',\n",
              " 'using',\n",
              " 'a',\n",
              " 'different',\n",
              " 'approach',\n",
              " ',',\n",
              " 'I',\n",
              " 'like',\n",
              " 'to',\n",
              " 'vet',\n",
              " 'every',\n",
              " 'single',\n",
              " 'one',\n",
              " 'of',\n",
              " 'them',\n",
              " '.',\n",
              " 'I',\n",
              " 'want',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'they',\n",
              " 'make',\n",
              " 'me',\n",
              " 'feel',\n",
              " 'good',\n",
              " ',',\n",
              " 'I',\n",
              " 'can',\n",
              " 'assume',\n",
              " 'that',\n",
              " 'that',\n",
              " 'make',\n",
              " 'my',\n",
              " 'community',\n",
              " 'of',\n",
              " 'friends',\n",
              " 'on',\n",
              " 'Twitter',\n",
              " 'feel',\n",
              " 'good',\n",
              " 'as',\n",
              " 'well',\n",
              " '...',\n",
              " 'by',\n",
              " 'proxySo',\n",
              " 'I',\n",
              " \"'ll\",\n",
              " 'share',\n",
              " 'my',\n",
              " 'stash',\n",
              " 'of',\n",
              " 'quotes',\n",
              " 'with',\n",
              " 'you',\n",
              " ',',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'going',\n",
              " 'to',\n",
              " 'pull',\n",
              " 'one',\n",
              " 'quote',\n",
              " 'for',\n",
              " 'every',\n",
              " 'author',\n",
              " '.',\n",
              " 'I',\n",
              " 'have',\n",
              " 'dozens',\n",
              " 'and',\n",
              " 'dozens',\n",
              " 'of',\n",
              " 'quotes',\n",
              " 'from',\n",
              " 'Albert',\n",
              " 'Einstein',\n",
              " 'or',\n",
              " 'Richard',\n",
              " 'Feynman',\n",
              " ',',\n",
              " 'but',\n",
              " 'here',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'on',\n",
              " 'the',\n",
              " 'pull',\n",
              " 'one',\n",
              " 'of',\n",
              " 'each',\n",
              " '.',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'assuming',\n",
              " 'if',\n",
              " 'you',\n",
              " 'like',\n",
              " 'this',\n",
              " 'project',\n",
              " 'and',\n",
              " 'you',\n",
              " 'want',\n",
              " 'to',\n",
              " 'build',\n",
              " 'your',\n",
              " 'own',\n",
              " 'quote',\n",
              " 'machine',\n",
              " ',',\n",
              " 'you',\n",
              " 'will',\n",
              " 'want',\n",
              " 'to',\n",
              " 'go',\n",
              " 'out',\n",
              " 'and',\n",
              " 'find',\n",
              " 'your',\n",
              " 'own',\n",
              " 'quotes',\n",
              " ',',\n",
              " 'those',\n",
              " 'that',\n",
              " 'make',\n",
              " 'you',\n",
              " 'feel',\n",
              " 'good',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VuAWGXwBnJL",
        "outputId": "f1ac4440-b77c-4118-bb91-0836f168c0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in doc:\n",
        "  print(word_tokenize(i),end=(\"\\n------------------------\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrR_wyjkBqPi",
        "outputId": "f8032d5d-5698-49ac-e19b-d072dea336b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Collecting', 'Quotes', 'As', 'we', 'are', 'going', 'to', 'use', 'famous', 'quotes', 'as', 'our', 'data', ',', 'we', 'are', 'facing', 'easy', 'situation', ',', 'quotes', 'are', 'plentiful', 'on', 'the', 'Internet', '.']\n",
            "------------------------\n",
            "['You', 'probably', 'could', 'even', 'buy', 'huge', 'repository', 'full', 'of', 'quotes', '.']\n",
            "------------------------\n",
            "['But', 'I', 'am', 'using', 'a', 'different', 'approach', ',', 'I', 'like', 'to', 'vet', 'every', 'single', 'one', 'of', 'them', '.']\n",
            "------------------------\n",
            "['I', 'want', 'make', 'sure', 'they', 'make', 'me', 'feel', 'good', ',', 'I', 'can', 'assume', 'that', 'that', 'make', 'my', 'community', 'of', 'friends', 'on', 'Twitter', 'feel', 'good', 'as', 'well', '...', 'by', 'proxySo', 'I', \"'ll\", 'share', 'my', 'stash', 'of', 'quotes', 'with', 'you', ',', 'I', \"'m\", 'going', 'to', 'pull', 'one', 'quote', 'for', 'every', 'author', '.']\n",
            "------------------------\n",
            "['I', 'have', 'dozens', 'and', 'dozens', 'of', 'quotes', 'from', 'Albert', 'Einstein', 'or', 'Richard', 'Feynman', ',', 'but', 'here', 'I', \"'m\", 'on', 'the', 'pull', 'one', 'of', 'each', '.']\n",
            "------------------------\n",
            "['I', \"'m\", 'assuming', 'if', 'you', 'like', 'this', 'project', 'and', 'you', 'want', 'to', 'build', 'your', 'own', 'quote', 'machine', ',', 'you', 'will', 'want', 'to', 'go', 'out', 'and', 'find', 'your', 'own', 'quotes', ',', 'those', 'that', 'make', 'you', 'feel', 'good', '.']\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if we use punct it treat ' as single word also others\n",
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "m7HxiEWKB_U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct=wordpunct_tokenize(corpus)\n",
        "wordpunct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z3WDxjKCUfB",
        "outputId": "a08faff6-803b-4c5f-89af-4c88e67069af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting',\n",
              " 'Quotes',\n",
              " 'As',\n",
              " 'we',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'use',\n",
              " 'famous',\n",
              " 'quotes',\n",
              " 'as',\n",
              " 'our',\n",
              " 'data',\n",
              " ',',\n",
              " 'we',\n",
              " 'are',\n",
              " 'facing',\n",
              " 'easy',\n",
              " 'situation',\n",
              " ',',\n",
              " 'quotes',\n",
              " 'are',\n",
              " 'plentiful',\n",
              " 'on',\n",
              " 'the',\n",
              " 'Internet',\n",
              " '.',\n",
              " 'You',\n",
              " 'probably',\n",
              " 'could',\n",
              " 'even',\n",
              " 'buy',\n",
              " 'huge',\n",
              " 'repository',\n",
              " 'full',\n",
              " 'of',\n",
              " 'quotes',\n",
              " '.',\n",
              " 'But',\n",
              " 'I',\n",
              " 'am',\n",
              " 'using',\n",
              " 'a',\n",
              " 'different',\n",
              " 'approach',\n",
              " ',',\n",
              " 'I',\n",
              " 'like',\n",
              " 'to',\n",
              " 'vet',\n",
              " 'every',\n",
              " 'single',\n",
              " 'one',\n",
              " 'of',\n",
              " 'them',\n",
              " '.',\n",
              " 'I',\n",
              " 'want',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'they',\n",
              " 'make',\n",
              " 'me',\n",
              " 'feel',\n",
              " 'good',\n",
              " ',',\n",
              " 'I',\n",
              " 'can',\n",
              " 'assume',\n",
              " 'that',\n",
              " 'that',\n",
              " 'make',\n",
              " 'my',\n",
              " 'community',\n",
              " 'of',\n",
              " 'friends',\n",
              " 'on',\n",
              " 'Twitter',\n",
              " 'feel',\n",
              " 'good',\n",
              " 'as',\n",
              " 'well',\n",
              " '...',\n",
              " 'by',\n",
              " 'proxySo',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'll',\n",
              " 'share',\n",
              " 'my',\n",
              " 'stash',\n",
              " 'of',\n",
              " 'quotes',\n",
              " 'with',\n",
              " 'you',\n",
              " ',',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'going',\n",
              " 'to',\n",
              " 'pull',\n",
              " 'one',\n",
              " 'quote',\n",
              " 'for',\n",
              " 'every',\n",
              " 'author',\n",
              " '.',\n",
              " 'I',\n",
              " 'have',\n",
              " 'dozens',\n",
              " 'and',\n",
              " 'dozens',\n",
              " 'of',\n",
              " 'quotes',\n",
              " 'from',\n",
              " 'Albert',\n",
              " 'Einstein',\n",
              " 'or',\n",
              " 'Richard',\n",
              " 'Feynman',\n",
              " ',',\n",
              " 'but',\n",
              " 'here',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'pull',\n",
              " 'one',\n",
              " 'of',\n",
              " 'each',\n",
              " '.',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'assuming',\n",
              " 'if',\n",
              " 'you',\n",
              " 'like',\n",
              " 'this',\n",
              " 'project',\n",
              " 'and',\n",
              " 'you',\n",
              " 'want',\n",
              " 'to',\n",
              " 'build',\n",
              " 'your',\n",
              " 'own',\n",
              " 'quote',\n",
              " 'machine',\n",
              " ',',\n",
              " 'you',\n",
              " 'will',\n",
              " 'want',\n",
              " 'to',\n",
              " 'go',\n",
              " 'out',\n",
              " 'and',\n",
              " 'find',\n",
              " 'your',\n",
              " 'own',\n",
              " 'quotes',\n",
              " ',',\n",
              " 'those',\n",
              " 'that',\n",
              " 'make',\n",
              " 'you',\n",
              " 'feel',\n",
              " 'good',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#treeword tokenize treat fullstop as same word except @ last position\n",
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "SzIfFIM4C1-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treeword_obj=TreebankWordTokenizer()\n",
        "treeword=treeword_obj.tokenize(corpus)\n",
        "treeword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_4oRcHHDD6l",
        "outputId": "00963761-b758-4d61-e6f5-e8e52e5d54dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting',\n",
              " 'Quotes',\n",
              " 'As',\n",
              " 'we',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'use',\n",
              " 'famous',\n",
              " 'quotes',\n",
              " 'as',\n",
              " 'our',\n",
              " 'data',\n",
              " ',',\n",
              " 'we',\n",
              " 'are',\n",
              " 'facing',\n",
              " 'easy',\n",
              " 'situation',\n",
              " ',',\n",
              " 'quotes',\n",
              " 'are',\n",
              " 'plentiful',\n",
              " 'on',\n",
              " 'the',\n",
              " 'Internet.',\n",
              " 'You',\n",
              " 'probably',\n",
              " 'could',\n",
              " 'even',\n",
              " 'buy',\n",
              " 'huge',\n",
              " 'repository',\n",
              " 'full',\n",
              " 'of',\n",
              " 'quotes.',\n",
              " 'But',\n",
              " 'I',\n",
              " 'am',\n",
              " 'using',\n",
              " 'a',\n",
              " 'different',\n",
              " 'approach',\n",
              " ',',\n",
              " 'I',\n",
              " 'like',\n",
              " 'to',\n",
              " 'vet',\n",
              " 'every',\n",
              " 'single',\n",
              " 'one',\n",
              " 'of',\n",
              " 'them.',\n",
              " 'I',\n",
              " 'want',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'they',\n",
              " 'make',\n",
              " 'me',\n",
              " 'feel',\n",
              " 'good',\n",
              " ',',\n",
              " 'I',\n",
              " 'can',\n",
              " 'assume',\n",
              " 'that',\n",
              " 'that',\n",
              " 'make',\n",
              " 'my',\n",
              " 'community',\n",
              " 'of',\n",
              " 'friends',\n",
              " 'on',\n",
              " 'Twitter',\n",
              " 'feel',\n",
              " 'good',\n",
              " 'as',\n",
              " 'well',\n",
              " '...',\n",
              " 'by',\n",
              " 'proxySo',\n",
              " 'I',\n",
              " \"'ll\",\n",
              " 'share',\n",
              " 'my',\n",
              " 'stash',\n",
              " 'of',\n",
              " 'quotes',\n",
              " 'with',\n",
              " 'you',\n",
              " ',',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'going',\n",
              " 'to',\n",
              " 'pull',\n",
              " 'one',\n",
              " 'quote',\n",
              " 'for',\n",
              " 'every',\n",
              " 'author.',\n",
              " 'I',\n",
              " 'have',\n",
              " 'dozens',\n",
              " 'and',\n",
              " 'dozens',\n",
              " 'of',\n",
              " 'quotes',\n",
              " 'from',\n",
              " 'Albert',\n",
              " 'Einstein',\n",
              " 'or',\n",
              " 'Richard',\n",
              " 'Feynman',\n",
              " ',',\n",
              " 'but',\n",
              " 'here',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'on',\n",
              " 'the',\n",
              " 'pull',\n",
              " 'one',\n",
              " 'of',\n",
              " 'each.',\n",
              " 'I',\n",
              " \"'m\",\n",
              " 'assuming',\n",
              " 'if',\n",
              " 'you',\n",
              " 'like',\n",
              " 'this',\n",
              " 'project',\n",
              " 'and',\n",
              " 'you',\n",
              " 'want',\n",
              " 'to',\n",
              " 'build',\n",
              " 'your',\n",
              " 'own',\n",
              " 'quote',\n",
              " 'machine',\n",
              " ',',\n",
              " 'you',\n",
              " 'will',\n",
              " 'want',\n",
              " 'to',\n",
              " 'go',\n",
              " 'out',\n",
              " 'and',\n",
              " 'find',\n",
              " 'your',\n",
              " 'own',\n",
              " 'quotes',\n",
              " ',',\n",
              " 'those',\n",
              " 'that',\n",
              " 'make',\n",
              " 'you',\n",
              " 'feel',\n",
              " 'good',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wordpunct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjrNo8zlCXkd",
        "outputId": "bc22e1f9-feab-4d26-90f6-8fd05f93e921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h88W31TUCb6m",
        "outputId": "61c479fa-ec4c-4baf-c68b-f7f97e9cadf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(treeword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnYY-o1ACdO3",
        "outputId": "21354637-8eda-4422-bd93-3cb7153f3968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcTTfsnFDcVO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}